{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp\n",
    "ru=pd.read_csv('../../data/00-raw-data/rumor.csv')\n",
    "#There are mutiple languages in the data set,so I firstly drop the unstructured data which is not written in English.\n",
    "ru=ru[ru[\"language\"]==\"english\"]\n",
    "#since the data set is collected by crawled during a certain period, so I drop the date of crawling and in case it will cause skew in the model trained\n",
    "ru.drop(labels=[\"crawled\",\"published\"],axis=1,inplace=True)\n",
    "#Columns like id, img_url,spam_score are useless, we need to drop them. The values of ord_in_thread are 0 for all rows, which is meaningless. We also drop it.\n",
    "ru.drop(labels=[\"main_img_url\",\"spam_score\"],axis=1,inplace=True)\n",
    "#add a label\n",
    "ru[\"label\"]=\"rumor\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid                     0\n",
       "ord_in_thread            0\n",
       "author                2209\n",
       "title                  680\n",
       "text                    46\n",
       "language                 0\n",
       "site_url                 0\n",
       "country                176\n",
       "domain_rank           4175\n",
       "thread_title            12\n",
       "replies_count            0\n",
       "participants_count       0\n",
       "likes                    0\n",
       "comments                 0\n",
       "shares                   0\n",
       "type                     0\n",
       "label                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru.isna().sum()# see whether there are some na value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I transformed the value of author as 0/1. 0 means anonymous, while 1 means the name of writer is recorded. All Na values were also be considered as anonymous.\n",
    "ru[\"author\"]=ru[\"author\"].fillna('Anonymous')\n",
    "ru[\"author\"]=ru[\"author\"].apply(lambda x:0 if x== \"Anonymous\" else 1 )\n",
    "# We cannot replace data with missing value of unstructed data. There is not a properly way to fill na in country.So we just drop certain rows.\n",
    "ru.drop(ru[ru[\"title\"].isna() | ru[\"text\"].isna() | ru[\"country\"].isna()].index,inplace=True)\n",
    "#For domain_rank column, we fill na with the median becasue the range of the values is huge.\n",
    "ru[\"domain_rank\"].fillna(ru[\"domain_rank\"].median())\n",
    "#Finally we delete the rows where its type is \"satire\",\"junksci\" and \"state\" to ensure it is a rumor. This will increase the quality of the data\n",
    "ru=ru[~ru[\"type\"].isin([\"satire\",\"junksci\",\"state\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the sentence so that we only have English words.\n",
    "ru[\"title\"]=ru['title'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model and fit the model to the data\n",
    "vectorizer = CountVectorizer()\n",
    "# change the dtype to int32 to decrease the size of data.\n",
    "matrix = vectorizer.fit_transform(ru.title).astype(\"int32\")\n",
    "#transform the result to a dataframe\n",
    "counts = pd.DataFrame(matrix.toarray(),columns=vectorizer.get_feature_names_out(),index=ru.uuid)\n",
    "#merge the dfs\n",
    "ru=pd.merge(ru,counts,on=\"uuid\")\n",
    "#drop the uuid,which is useless\n",
    "ru.drop(columns=(\"uuid\"),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the data\n",
    "ru.to_csv(\"../../data/01-modified-data/labeled_rumor_python.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efe839fab88ae80421cffb56f789661a42a9e93ca30a0c0f003df392ed76a9d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
