[
  {
    "objectID": "ARM.html",
    "href": "ARM.html",
    "title": "",
    "section": "",
    "text": "In this tab, we try to use ARM (Association Rule Mining). This tab researches on the account descrption written by the users who sending rumors(which is the “description” column in the “cleaned_rumor_manually.csv” data set) to *** find the features tell users tending to spread rumors ***"
  },
  {
    "objectID": "ARM.html#theory",
    "href": "ARM.html#theory",
    "title": "",
    "section": "Theory",
    "text": "Theory\nARM searches for the relationship between different things, recording when items happened together or they are correlated. There exist 3 metrics(support, confidence, lift) when we try to find the pattern: how many instance support our rule(by calculating how often the items appear together), how confident we are for patterns observed (by calculating the given probability of the rules), and how much the items are related."
  },
  {
    "objectID": "ARM.html#method",
    "href": "ARM.html#method",
    "title": "",
    "section": "Method",
    "text": "Method\nThis part will show the workflow of training the model with the method introduced before. \n\nData Selection\nThe features we use is shown below. As mentioned before, I only choose the description of the positive instances.\n\n\nCode\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom apyori import apriori\nimport networkx as nx \nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\n# read the data\ndf=pd.read_csv(\"../../data/01-modified-data/cleaned_supervised_data.csv\")\ndf=df[df[\"label\"]==1]\ndf[\"description\"].fillna(\"\",inplace=True)\n#replace the s(which is 's originally) and the t(which is 't originially) and re \ndf[\"description\"]=df[\"description\"].str.replace(\" s\",\"\")\ndf[\"description\"]=df[\"description\"].str.replace(\" t\",\"\")\ndf[\"description\"]=df[\"description\"].str.replace(\" re\",\"\")\ndf[\"description\"]=df[\"description\"].str.replace(\" w\",\"\")\n# drop the stopwords\ndef drop_stop(word_list):\n    return[word for word in word_list if word not in stopwords.words('english')]\ndf[\"description\"]=df[\"description\"].apply(word_tokenize)\ndf=df[\"description\"].apply(drop_stop)\ndf.head()\n\n\n0    [make, america, florida, let, haveome, fun, ad...\n1    [libertarian, free, markets, freepeech, elfish...\n2    [urvivor, yazidigenocide, human, rights, activ...\n3                                         [cope, fest]\n4    [feminist, cymraes, european, fbpe, fbppr, fbeie]\nName: description, dtype: object\n\n\n\n\n\nModel Building\n\n\nCode\ndef reformat_results(results):\n\n    keep =[]\n    for i in range(0, len(results)):\n        for j in range(0, len(list(results[i]))):\n            if (j>1):\n                for k in range(0, len(list(results[i][j]))):\n                    if (len(results[i][j][k][0]) != 0):\n                        rhs = list(results[i][j][k][0])\n                        lhs = list(results[i][j][k][1])\n                        conf = float(results[i][j][k][2])\n                        lift = float(results[i][j][k][3])\n                        keep.append([rhs,lhs,supp,conf,supp*conf,lift])\n            if (j==1):\n                supp = results[i][j]\n\n    return pd.DataFrame(keep, columns =[\"rhs\",\"lhs\",\"supp\",\"conf\",\"supp x conf\",\"lift\"])\n\ndef convert_to_network(df):\n    print(df)\n\n    #BUILD GRAPH\n    G = nx.DiGraph()  # DIRECTED\n    for row in df.iterrows():\n        # for column in df.columns:\n        lhs=\"_\".join(row[1][0])\n        rhs=\"_\".join(row[1][1])\n        conf=row[1][3]; #print(conf)\n        if(lhs not in G.nodes): \n            G.add_node(lhs)\n        if(rhs not in G.nodes): \n            G.add_node(rhs)\n\n        edge=(lhs,rhs)\n        if edge not in G.edges:\n            G.add_edge(lhs, rhs, weight=conf)\n    return G\n\ndef plot_network(G):\n    #SPECIFIY X-Y POSITIONS FOR PLOTTING\n    pos=nx.random_layout(G)\n\n    #GENERATE PLOT\n    fig, ax = plt.subplots()\n    fig.set_size_inches(15, 15)\n\n    #assign colors based on attributes\n    weights_e   = [G[u][v]['weight'] for u,v in G.edges()]\n\n    #SAMPLE CMAP FOR COLORS \n    cmap=plt.cm.get_cmap('Blues')\n    colors_e    = [cmap(G[u][v]['weight']*10) for u,v in G.edges()]\n\n    #PLOT\n    nx.draw(\n    G,\n    edgecolors=\"black\",\n    edge_color=colors_e,\n    node_size=2000,\n    linewidths=2,\n    font_size=8,\n    font_color=\"white\",\n    font_weight=\"bold\",\n    width=weights_e,\n    with_labels=True,\n    pos=pos,\n    ax=ax\n    )\n    ax.set(title='Account Description of Users Sending rumors')\n    plt.show()\n\n\nresults = list(apriori(df, min_support=0.02, min_confidence=0.2, min_length=3, max_length=2))\npd_results = reformat_results(results)\nG = convert_to_network(pd_results)\nplot_network(G)\n\n\n               rhs             lhs  supp      conf  supp x conf       lift\n0           [aime]          [host]  0.02  1.000000     0.020000  10.000000\n1        [america]       [freedom]  0.02  0.400000     0.008000   5.000000\n2        [freedom]       [america]  0.02  0.250000     0.005000   5.000000\n3         [author]   [bestselling]  0.02  0.500000     0.010000  25.000000\n4    [bestselling]        [author]  0.02  1.000000     0.020000  25.000000\n..             ...             ...   ...       ...          ...        ...\n56     [political]  [organization]  0.02  0.666667     0.013333  22.222222\n57  [organization]            [us]  0.02  0.666667     0.013333   9.523810\n58            [us]  [organization]  0.02  0.285714     0.005714   9.523810\n59     [political]            [us]  0.02  0.666667     0.013333   9.523810\n60            [us]     [political]  0.02  0.285714     0.005714   9.523810\n\n[61 rows x 6 columns]\n\n\n\n\n\n\n\n\nFinal Results\nAccording to the results, KMEAN and hierarchy clustering returns a similar result. They sepearte the accounts which are more active with the others.For DBSAN, the best number of group calculated based on mathematical method is not what we want(2 groups).\nThe reason may be that just based on the information about account, the meaning of group is not exactly what we target at. Tjat may shift to something like “whether they are more likely to tweet”.\nUnfortunately, clustering seems to fail to provide what we want."
  },
  {
    "objectID": "ARM.html#conclusion",
    "href": "ARM.html#conclusion",
    "title": "",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tab, we have used three separate clustering model with the best hyperparameters to conduct unsupervised learning.\nClustering is not a suitable candidate to meet our demand. This is mainly because the result is not what we want.\nTo be specific, the result clustering gives may refers to the active status. This give us a hint that active status may have some connections to the groups we want, but can not directly tell us whether they are easily be affected by rumors"
  },
  {
    "objectID": "ARM.html#reference",
    "href": "ARM.html#reference",
    "title": "",
    "section": "Reference",
    "text": "Reference\n[1]https://medium.com/towards-data-science/association-rule-mining-be4122fc1793\n[2]Brus, P. (2021, July 29). Clustering: How to find hyperparameters using inertia. Medium. Retrieved November 13, 2022, from https://medium.com/towards-data-science/clustering-how-to-find-hyperparameters-using-inertia-b0343c6fe819"
  }
]